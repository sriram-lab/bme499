---
title: "Decision Trees and Random Forest"
author: "Joshua Sodicoff"
date: "11/15/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(ggplot2) #a popular plotting library
library(readxl) #a utility for reading excel files
```

# Decision Trees

In this lesson, we will apply decision trees to the task of predicting patient health data from the Framingham dataset. To accomplish this, we will be using the `rpart` library, which implements classification and regresssion trees.

In this demonstration, we will attempt to predict occurance of diabetes. First, let's read in the Framingham dataset and remove rows with missing values. We will also subset out temporal variables for simplicity's sake.

```{r read_in}
fram = readxl::read_excel("frmgham2.xls")
missing_vals = apply(fram, MARGIN = 1, function(x){return(any(is.na(x)))}) #determines if any of the values are missing by row
fram = fram[!missing_vals,1:31] #subsets to the rows without missing values, non time columns
fram$DIABETES = as.factor(fram$DIABETES) #ensures the variable is categorical
```

To build the model, we use the `rpart` function, which takes a formula, a source data frame, and a method. The formula `DIABETES ~ .` represents diabetes a function of all other features. For classification, method should equal `"class"`.

```{r trees}
library(rpart) #load rpart
diab_model = rpart(DIABETES~.,data = fram, method = "class") #generate the model
```

We can view details about the model, including relative error by number of splits, the importance of  variables, and information on the tree structure itself with the `summary` function.

```{r view_tree}
summary(diab_model)
```

We can also read a brief description of the tree's structure with the `print` function.

```{r print_tree}
print(diab_model)
```

Or we can view a visual representation of the tree by sequentially calling `plot` and `text`.

```{r plot_tree, fig.width = 8, fig.height= 6}
plot(diab_model)
text(diab_model)
```

#### Question

Can you interpret the generated tree model? What do the interpolated splits tell you about diabetes occurance? Do the splits and leaves make sense?


We may want to calculate the resubstitution error, which quantifies the accuracy of the model on the training data. Though there is not a built-in function to complete this, we can calculate it easily.

```{r resub}
pred_diab = predict(diab_model, fram, type = "class")

resub_error = 1 - sum(pred_diab == fram$DIABETES)/(length(pred_diab)) #equal to the fraction of predictions that are not equal
resub_error
```
To find cross validation error, we view the `cptable` element of the `diab_model` object. The `xerror` column refers to the cross validation error, run with a default value of 10.

```{r cross_val_built}
diab_model[["cptable"]]
```

We can change the number of folds by passing the `part.control` function with its `xval` parameter equal to the number of folds to the `control` parameter of the `rpart` function. We'll touch on `control` soon.

```{r cross_val_param}
control_args = rpart.control(xval = 5)
diab_model_k_5 = rpart(DIABETES~.,data = fram, method = "class",
                   control = control_args)
```

We can also (manually) calculate the cross-validation error.

```{r cross_val}
K = 10 #determine the number of folds
errors = c() #create a variable to store error values in
folds = rep_len(1:K,nrow(fram)) #generate a vector matching samples to a fold
folds = sample(folds,nrow(fram), replace = FALSE) #permute the original vector to retain equal counts but randomize the order
for(k in 1:K){ #for each fold
  model = rpart(DIABETES~.,data = fram[folds != k,], method = "class") #build the model using the subset of data outside of the fold
  prediction = predict(model, fram[folds == k, ], type = "class") #predict the output for the fold
  errors = c(errors, 1- sum(prediction == fram$DIABETES[folds == k])/(length(prediction)))
  #calcuate the error
}
mean(errors) #average the error across all folds
```

To prune the tree, we first want to determine the optimal complexity parameter. We can view a heuristic of complexity parameter versus cross-validation error with the `plotcp` function. The top x axis represents the `cp` value and the top is the number of leaves at that complexity.

```{r plot_diab}
plotcp(diab_model, upper = "size");
```

#### Question

Why might we choose a model that doesn't have the lowest error? In what cases would you expect a simpler model to have better performance?

This plot demonstrates that the decrease in error slows when `cp = 0.017`. We then use the `prune` function.

```{r prune}
pruned_diab_model = prune(diab_model, cp = 0.017)
```

We see that this new model makes decisions based off of three splits.

```{r plot_pruned_tree, fig.width=8, fig.height=6}
plot(pruned_diab_model)
text(pruned_diab_model)
```

Finally, to assess the results of this model, let's generate a confusion matrix. There isn't a built-in function for this, but we can pretty easily compute the values for all conditions.

```{r confusion_matrix}
pred_diab_pruned = predict(pruned_diab_model, fram, type = "class")
confusion_mat = matrix(c(sum(pred_diab_pruned == fram$DIABETES & pred_diab_pruned == 1), #true positive
                         sum(pred_diab_pruned != fram$DIABETES & pred_diab_pruned == 1), #false positive
                         sum(pred_diab_pruned != fram$DIABETES & pred_diab_pruned == 0), #false negative
                         sum(pred_diab_pruned == fram$DIABETES & pred_diab_pruned == 0) #true negative
                        ), nrow = 2)
confusion_mat
```

Let's also try this for the original model to compare the differences in predictions.

```{r confusion_matrix_2}
confusion_mat = matrix(c(sum(pred_diab == fram$DIABETES & pred_diab == 1), #true positive
                         sum(pred_diab != fram$DIABETES & pred_diab == 1), #false positive
                         sum(pred_diab != fram$DIABETES & pred_diab == 0), #false negative
                         sum(pred_diab == fram$DIABETES & pred_diab == 0) #true negative
                        ), nrow = 2)
confusion_mat
```

#### Note

When you grow a decision tree, consider its simplicity and predictive power. A deep tree with many leaves is usually highly accurate on the training data. However, the tree is not guaranteed to show a comparable accuracy on an independent test set. A leafy tree tends to overtrain (or overfit), and its test accuracy is often far less than its training (resubstitution) accuracy. In contrast, a shallow tree does not attain high training accuracy. But a shallow tree can be more robust â€” its training accuracy could be close to that of a representative test set. Also, a shallow tree is easy to interpret. If you do not have enough data for training and test, estimate tree accuracy by cross validation.

# Random Forest

Now, let's try a similar task using a Random Forest model instead. The `randomForest` package implements the algorithm in R. 

```{r rf_load, message=FALSE,warning=FALSE, results="hide"}
library(randomForest)
```

We can then build the model using the `randomForest` function. For this example, we will predict occurance of stroke from the Framingham dataset.Note that the function attempts to infer if regression or classification should be completed, so the desired response variable should be converted to a factor before running the function.

```{r rf}
fram$STROKE = as.factor(fram$STROKE)
stroke_model_rf = randomForest(STROKE~.,data = fram, importance = TRUE)
```

The `randomForest` function also takes several hyperparameters, including

* `ntree` - the number of trees to include in the ensemble, default 500
* `mtry` - the number of features to randomly use at each split, default the square root of the number of features
* `maxnodes` - the maximum number of leaves in a tree
* `nodesize` - the minimum size of a leaf

To get basic information about the model, use `print`.

```{r print_rf}
print(stroke_model_rf)
```

To determine the out of bag error of the model, we look at the final element in the `OOB` column of the `err.rate` element of the model object.

```{r oob_errr}
stroke_model_rf$err.rate[500,"OOB"]
```

Let's also assess the resubstitution error. Just like with `rpart`, we can pass our model as a parameter to the `predict` function.

```{r predict_rf}
pred_stroke = predict(stroke_model_rf, fram)
resub_error = 1 - sum(pred_stroke == fram$STROKE)/(length(pred_stroke)) #equal to the fraction of predictions that are not equal
resub_error
```

`randomForest` also determines the importance of features using both mean decrease in accuracy and mean decrease in Gini coefficient

```{r importance}
importance(stroke_model_rf)
```

This data is pretty helpful! We can also visualize importance with the `varImpPlot` function.

```{r var_imp, fig.width = 8, fig.height=6}
varImpPlot(stroke_model_rf)
```


What if an ensemble needs more trees? We can use the `grow` function to add an arbitrary number of trees.

```{r grow}
stroke_model_rf_1000 = grow(stroke_model_rf, 500)
```

Let's assess the accuracy of the expanded ensemble using a confusion matrix

```{r confusion_matrix_rf}
pred_stroke_1000 = predict(stroke_model_rf_1000, fram, type = "class")
confusion_mat = matrix(c(sum(pred_stroke_1000 == fram$STROKE & pred_stroke_1000 == 1), #true positive
                         sum(pred_stroke_1000 != fram$STROKE & pred_stroke_1000 == 1), #false positive
                         sum(pred_stroke_1000 != fram$STROKE & pred_stroke_1000 == 0), #false negative
                         sum(pred_stroke_1000 == fram$STROKE & pred_stroke_1000 == 0) #true negative
                        ), nrow = 2)
confusion_mat
```

### Function glossary
* `rep_len` - generates a vector with equal to the second parameter by repeating the first argument
* `matrix` - converts the arguments into a matrix